{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"Time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:29]\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 42)\n",
    "x_smote, y_smote = sm.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.concat([pd.DataFrame(x_smote),pd.DataFrame(y_smote)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=1.96\n",
    "p=0.5\n",
    "E=0.06\n",
    "SS=(Z**2)*p*(1-p)/(E**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>-0.088736</td>\n",
       "      <td>0.506421</td>\n",
       "      <td>0.517709</td>\n",
       "      <td>0.045882</td>\n",
       "      <td>0.831691</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>0.293880</td>\n",
       "      <td>0.139598</td>\n",
       "      <td>-0.109933</td>\n",
       "      <td>-0.135794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133305</td>\n",
       "      <td>-0.364931</td>\n",
       "      <td>0.114046</td>\n",
       "      <td>-1.263114</td>\n",
       "      <td>-1.294712</td>\n",
       "      <td>0.090176</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>0.175224</td>\n",
       "      <td>-0.342306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.238722</td>\n",
       "      <td>0.508945</td>\n",
       "      <td>0.409724</td>\n",
       "      <td>0.164189</td>\n",
       "      <td>0.710232</td>\n",
       "      <td>0.202159</td>\n",
       "      <td>0.240898</td>\n",
       "      <td>0.131461</td>\n",
       "      <td>-0.142607</td>\n",
       "      <td>-0.146215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143091</td>\n",
       "      <td>-0.419863</td>\n",
       "      <td>0.143665</td>\n",
       "      <td>-1.212665</td>\n",
       "      <td>-1.159160</td>\n",
       "      <td>0.082870</td>\n",
       "      <td>0.196184</td>\n",
       "      <td>0.198341</td>\n",
       "      <td>-0.341040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>-0.920531</td>\n",
       "      <td>1.282437</td>\n",
       "      <td>-0.904356</td>\n",
       "      <td>2.588073</td>\n",
       "      <td>-0.290957</td>\n",
       "      <td>-0.892684</td>\n",
       "      <td>-1.560927</td>\n",
       "      <td>0.872741</td>\n",
       "      <td>-1.771356</td>\n",
       "      <td>-1.737542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222137</td>\n",
       "      <td>-0.274786</td>\n",
       "      <td>-0.240218</td>\n",
       "      <td>0.058052</td>\n",
       "      <td>0.093232</td>\n",
       "      <td>0.157209</td>\n",
       "      <td>0.153860</td>\n",
       "      <td>-0.080524</td>\n",
       "      <td>-0.341914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1.228478</td>\n",
       "      <td>-1.097948</td>\n",
       "      <td>1.629013</td>\n",
       "      <td>-0.005550</td>\n",
       "      <td>-1.969868</td>\n",
       "      <td>0.250276</td>\n",
       "      <td>-1.381782</td>\n",
       "      <td>0.174507</td>\n",
       "      <td>0.641162</td>\n",
       "      <td>0.208170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526064</td>\n",
       "      <td>-0.566475</td>\n",
       "      <td>0.045969</td>\n",
       "      <td>0.475350</td>\n",
       "      <td>0.164650</td>\n",
       "      <td>1.069437</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>-0.195834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>1.295949</td>\n",
       "      <td>0.136054</td>\n",
       "      <td>0.383682</td>\n",
       "      <td>-0.079325</td>\n",
       "      <td>-0.497416</td>\n",
       "      <td>-1.120717</td>\n",
       "      <td>0.075887</td>\n",
       "      <td>-0.316257</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>-0.232533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092651</td>\n",
       "      <td>-0.185626</td>\n",
       "      <td>0.027576</td>\n",
       "      <td>0.496765</td>\n",
       "      <td>0.287257</td>\n",
       "      <td>0.955182</td>\n",
       "      <td>-0.075089</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>-0.323596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>-0.809580</td>\n",
       "      <td>0.120395</td>\n",
       "      <td>0.863516</td>\n",
       "      <td>-0.306409</td>\n",
       "      <td>0.647796</td>\n",
       "      <td>-0.225396</td>\n",
       "      <td>0.158797</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>-0.064949</td>\n",
       "      <td>-0.098289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194201</td>\n",
       "      <td>-0.333627</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>-0.269930</td>\n",
       "      <td>-0.175830</td>\n",
       "      <td>0.204047</td>\n",
       "      <td>-0.238565</td>\n",
       "      <td>-0.257299</td>\n",
       "      <td>-0.339550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1.211111</td>\n",
       "      <td>0.345933</td>\n",
       "      <td>0.315431</td>\n",
       "      <td>0.673364</td>\n",
       "      <td>-0.352563</td>\n",
       "      <td>-1.058865</td>\n",
       "      <td>0.089449</td>\n",
       "      <td>-0.197810</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>-0.279454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286011</td>\n",
       "      <td>-0.823307</td>\n",
       "      <td>0.122377</td>\n",
       "      <td>0.330985</td>\n",
       "      <td>0.207881</td>\n",
       "      <td>0.096834</td>\n",
       "      <td>-0.028063</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>-0.333837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>-0.671983</td>\n",
       "      <td>1.286814</td>\n",
       "      <td>1.575214</td>\n",
       "      <td>-0.289993</td>\n",
       "      <td>0.601959</td>\n",
       "      <td>-0.399923</td>\n",
       "      <td>1.466422</td>\n",
       "      <td>-0.792099</td>\n",
       "      <td>0.747273</td>\n",
       "      <td>1.206007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.535865</td>\n",
       "      <td>-0.529531</td>\n",
       "      <td>-0.112928</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>-0.183674</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>-0.065969</td>\n",
       "      <td>-0.620860</td>\n",
       "      <td>-0.266392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1.254589</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.301788</td>\n",
       "      <td>0.691854</td>\n",
       "      <td>-0.369250</td>\n",
       "      <td>-1.065173</td>\n",
       "      <td>0.085929</td>\n",
       "      <td>-0.201354</td>\n",
       "      <td>0.033659</td>\n",
       "      <td>-0.282022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287274</td>\n",
       "      <td>-0.831683</td>\n",
       "      <td>0.127945</td>\n",
       "      <td>0.335932</td>\n",
       "      <td>0.215693</td>\n",
       "      <td>0.094864</td>\n",
       "      <td>-0.023280</td>\n",
       "      <td>0.030809</td>\n",
       "      <td>-0.333712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>-0.703191</td>\n",
       "      <td>-1.373177</td>\n",
       "      <td>1.532175</td>\n",
       "      <td>0.858871</td>\n",
       "      <td>1.485859</td>\n",
       "      <td>0.319288</td>\n",
       "      <td>-1.284646</td>\n",
       "      <td>0.502553</td>\n",
       "      <td>0.465354</td>\n",
       "      <td>-0.262935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159017</td>\n",
       "      <td>0.450044</td>\n",
       "      <td>0.217961</td>\n",
       "      <td>-0.646895</td>\n",
       "      <td>-0.062254</td>\n",
       "      <td>0.562270</td>\n",
       "      <td>-0.077627</td>\n",
       "      <td>-0.095559</td>\n",
       "      <td>-0.337285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5        V6        V7  \\\n",
       "785  -0.088736  0.506421  0.517709  0.045882  0.831691  0.202842  0.293880   \n",
       "842   0.238722  0.508945  0.409724  0.164189  0.710232  0.202159  0.240898   \n",
       "850  -0.920531  1.282437 -0.904356  2.588073 -0.290957 -0.892684 -1.560927   \n",
       "526   1.228478 -1.097948  1.629013 -0.005550 -1.969868  0.250276 -1.381782   \n",
       "678   1.295949  0.136054  0.383682 -0.079325 -0.497416 -1.120717  0.075887   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "950  -0.809580  0.120395  0.863516 -0.306409  0.647796 -0.225396  0.158797   \n",
       "1135  1.211111  0.345933  0.315431  0.673364 -0.352563 -1.058865  0.089449   \n",
       "518  -0.671983  1.286814  1.575214 -0.289993  0.601959 -0.399923  1.466422   \n",
       "1374  1.254589  0.349854  0.301788  0.691854 -0.369250 -1.065173  0.085929   \n",
       "1109 -0.703191 -1.373177  1.532175  0.858871  1.485859  0.319288 -1.284646   \n",
       "\n",
       "            V8        V9       V10  ...       V21       V22       V23  \\\n",
       "785   0.139598 -0.109933 -0.135794  ... -0.133305 -0.364931  0.114046   \n",
       "842   0.131461 -0.142607 -0.146215  ... -0.143091 -0.419863  0.143665   \n",
       "850   0.872741 -1.771356 -1.737542  ...  0.222137 -0.274786 -0.240218   \n",
       "526   0.174507  0.641162  0.208170  ... -0.526064 -0.566475  0.045969   \n",
       "678  -0.316257  0.039229 -0.232533  ... -0.092651 -0.185626  0.027576   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "950   0.123028 -0.064949 -0.098289  ... -0.194201 -0.333627 -0.146749   \n",
       "1135 -0.197810  0.034983 -0.279454  ... -0.286011 -0.823307  0.122377   \n",
       "518  -0.792099  0.747273  1.206007  ... -0.535865 -0.529531 -0.112928   \n",
       "1374 -0.201354  0.033659 -0.282022  ... -0.287274 -0.831683  0.127945   \n",
       "1109  0.502553  0.465354 -0.262935  ...  0.159017  0.450044  0.217961   \n",
       "\n",
       "           V24       V25       V26       V27       V28    Amount  Class  \n",
       "785  -1.263114 -1.294712  0.090176  0.180102  0.175224 -0.342306      1  \n",
       "842  -1.212665 -1.159160  0.082870  0.196184  0.198341 -0.341040      1  \n",
       "850   0.058052  0.093232  0.157209  0.153860 -0.080524 -0.341914      1  \n",
       "526   0.475350  0.164650  1.069437  0.027740  0.026680 -0.195834      0  \n",
       "678   0.496765  0.287257  0.955182 -0.075089  0.007082 -0.323596      0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "950  -0.269930 -0.175830  0.204047 -0.238565 -0.257299 -0.339550      1  \n",
       "1135  0.330985  0.207881  0.096834 -0.028063  0.024827 -0.333837      1  \n",
       "518   0.014225 -0.183674  0.001701 -0.065969 -0.620860 -0.266392      0  \n",
       "1374  0.335932  0.215693  0.094864 -0.023280  0.030809 -0.333712      1  \n",
       "1109 -0.646895 -0.062254  0.562270 -0.077627 -0.095559 -0.337285      1  \n",
       "\n",
       "[266 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_new.sample(int(SS))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.2429906542056\n",
      "96.26168224299066\n",
      "93.45794392523365\n",
      "94.39252336448598\n",
      "86.91588785046729\n"
     ]
    }
   ],
   "source": [
    "x=df1.iloc[:,:29]\n",
    "y=df1['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "accuracy1=[]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy1.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy1.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy1.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb_model = adb.fit(X_train,y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy1.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy1.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new\n",
    "cluster_size = 20 \n",
    "n_clusters = 28\n",
    "N = len(df)\n",
    "K = int(N/cluster_size)\n",
    "data = None\n",
    "for k in range(K):\n",
    "    sample_k = df.sample(cluster_size)\n",
    "    sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
    "    df = df.drop(index = sample_k.index)\n",
    "    data = pd.concat([data,sample_k],axis = 0)\n",
    "random_chosen_clusters = np.random.randint(0,K,size =n_clusters )\n",
    "df2=data[data.cluster.isin(random_chosen_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.5625\n",
      "100.0\n",
      "95.3125\n",
      "96.35416666666666\n",
      "90.625\n"
     ]
    }
   ],
   "source": [
    "x=df2.iloc[:,:29]\n",
    "y=df2['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "accuracy2=[]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy2.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy2.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy2.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb_model = adb.fit(X_train,y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy2.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy2.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1=(1.65**2)*0.5*0.5/((0.07/2)**2)\n",
    "df3=df_new.groupby('Class', group_keys=False).apply(lambda x: x.sample(int(n1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.66666666666666\n",
      "99.54954954954955\n",
      "93.24324324324324\n",
      "98.1981981981982\n",
      "90.31531531531532\n"
     ]
    }
   ],
   "source": [
    "x=df3.iloc[:,:29]\n",
    "y=df3['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "accuracy3=[]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy3.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy3.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy3.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb_model = adb.fit(X_train,y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy3.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy3.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_new\n",
    "step=5\n",
    "indexes = np.arange(0, len(df), step=step)\n",
    "df4 = df.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.86178861788618\n",
      "99.1869918699187\n",
      "91.05691056910568\n",
      "96.7479674796748\n",
      "91.05691056910568\n"
     ]
    }
   ],
   "source": [
    "x=df4.iloc[:,:29]\n",
    "y=df4['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "accuracy4=[]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy4.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy4.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy4.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb_model = adb.fit(X_train,y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy4.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy4.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.arange(0, len(df_new), step=5)\n",
    "df4 = df.iloc[indexes]\n",
    "df5 = df4.sample(int(SS) , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.02803738317756\n",
      "94.39252336448598\n",
      "90.65420560747664\n",
      "96.26168224299066\n",
      "84.11214953271028\n"
     ]
    }
   ],
   "source": [
    "x=df5.iloc[:,:29]\n",
    "y=df5['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "accuracy5=[]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy5.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy5.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy5.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "adb = AdaBoostClassifier()\n",
    "adb_model = adb.fit(X_train,y_train)\n",
    "y_pred = adb_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy5.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracy5.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Simple Random Sampling</th>\n",
       "      <th>Cluster Sampling</th>\n",
       "      <th>Stratified Sampling</th>\n",
       "      <th>Systematic Sampling</th>\n",
       "      <th>Multi-Stage Sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighbors Classifier</td>\n",
       "      <td>82.242991</td>\n",
       "      <td>76.562500</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>78.861789</td>\n",
       "      <td>71.028037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>96.261682</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.549550</td>\n",
       "      <td>99.186992</td>\n",
       "      <td>94.392523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support</td>\n",
       "      <td>93.457944</td>\n",
       "      <td>95.312500</td>\n",
       "      <td>93.243243</td>\n",
       "      <td>91.056911</td>\n",
       "      <td>90.654206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>94.392523</td>\n",
       "      <td>96.354167</td>\n",
       "      <td>98.198198</td>\n",
       "      <td>96.747967</td>\n",
       "      <td>96.261682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>86.915888</td>\n",
       "      <td>90.625000</td>\n",
       "      <td>90.315315</td>\n",
       "      <td>91.056911</td>\n",
       "      <td>84.112150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0  Simple Random Sampling  Cluster Sampling  \\\n",
       "0           KNeighbors Classifier               82.242991         76.562500   \n",
       "1        Random Forest Classifier               96.261682        100.000000   \n",
       "2                         Support               93.457944         95.312500   \n",
       "3             AdaBoost Classifier               94.392523         96.354167   \n",
       "4  Logistic Regression Classifier               86.915888         90.625000   \n",
       "\n",
       "   Stratified Sampling  Systematic Sampling  Multi-Stage Sampling  \n",
       "0            91.666667            78.861789             71.028037  \n",
       "1            99.549550            99.186992             94.392523  \n",
       "2            93.243243            91.056911             90.654206  \n",
       "3            98.198198            96.747967             96.261682  \n",
       "4            90.315315            91.056911             84.112150  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_models=['KNeighbors Classifier','Random Forest Classifier','Support','AdaBoost Classifier','Logistic Regression Classifier']\n",
    "Accuracy=pd.DataFrame(ML_models)\n",
    "Accuracy['Simple Random Sampling']=accuracy1\n",
    "Accuracy['Cluster Sampling']=accuracy2\n",
    "Accuracy['Stratified Sampling']=accuracy3\n",
    "Accuracy['Systematic Sampling']=accuracy4\n",
    "Accuracy['Multi-Stage Sampling']=accuracy5\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d8b2cce12626a75dd80ec0b1f091e4d58d5d6264935d28de4f6beb60559a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
